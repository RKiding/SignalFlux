import os
from typing import Optional, List, Dict, Any, Union
from agno.models.base import Model
from loguru import logger
from dotenv import load_dotenv
from utils.llm.factory import get_model
from utils.llm.capability import ModelCapabilityRegistry

# ç¡®ä¿åœ¨åˆå§‹åŒ–å‰åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class ModelRouter:
    """
    æ¨¡å‹è·¯ç”±ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†â€œæ¨ç†/å†™ä½œæ¨¡å‹â€ (Reasoning Model) å’Œâ€œå·¥å…·è°ƒç”¨æ¨¡å‹â€ (Tool Model)ã€‚
    2. æ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚
    """
    
    def __init__(self):
        # é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
        self.reasoning_provider = os.getenv("REASONING_MODEL_PROVIDER", os.getenv("LLM_PROVIDER", "openai"))
        self.reasoning_id = os.getenv("REASONING_MODEL_ID", os.getenv("LLM_MODEL", "gpt-4o"))
        self.reasoning_host = os.getenv("REASONING_MODEL_HOST", os.getenv("LLM_HOST"))
        
        self.tool_provider = os.getenv("TOOL_MODEL_PROVIDER", self.reasoning_provider)
        self.tool_id = os.getenv("TOOL_MODEL_ID", self.reasoning_id)
        self.tool_host = os.getenv("TOOL_MODEL_HOST", self.reasoning_host)
        
        self._reasoning_model = None
        self._tool_model = None
        
        logger.info(f"ğŸ¤– ModelRouter initialized: Reasoning={self.reasoning_id} ({self.reasoning_host or 'default'}), Tool={self.tool_id} ({self.tool_host or 'default'})")

    def get_reasoning_model(self, **kwargs) -> Model:
        if not self._reasoning_model:
            # ä¼˜å…ˆä½¿ç”¨è·¯ç”±é…ç½®çš„ host
            if self.reasoning_host and "host" not in kwargs:
                kwargs["host"] = self.reasoning_host
            self._reasoning_model = get_model(self.reasoning_provider, self.reasoning_id, **kwargs)
        return self._reasoning_model

    def get_tool_model(self, **kwargs) -> Model:
        if not self._tool_model:
            # ä¼˜å…ˆä½¿ç”¨è·¯ç”±é…ç½®çš„ host
            if self.tool_host and "host" not in kwargs:
                kwargs["host"] = self.tool_host
                
            # æ£€æŸ¥ tool_model æ˜¯å¦çœŸçš„æ”¯æŒ tool call
            caps = ModelCapabilityRegistry.get_capabilities(self.tool_provider, self.tool_id, **kwargs)
            if not caps["supports_tool_call"]:
                logger.warning(f"âš ï¸ Configured tool model {self.tool_id} might not support native tool calls! Consider using ReAct mode or a different model.")
            
            self._tool_model = get_model(self.tool_provider, self.tool_id, **kwargs)
        return self._tool_model

    def get_model_for_agent(self, has_tools: bool = False, **kwargs) -> Model:
        """
        æ ¹æ® Agent æ˜¯å¦åŒ…å«å·¥å…·æ¥è¿”å›åˆé€‚çš„æ¨¡å‹ã€‚
        """
        if has_tools:
            return self.get_tool_model(**kwargs)
        return self.get_reasoning_model(**kwargs)

# å…¨å±€å•ä¾‹
router = ModelRouter()
