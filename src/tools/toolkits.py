"""
SignalFlux å·¥å…·åŒ…å±‚ - Agno Toolkit é€‚é…å™¨
å¤ç”¨ utils ä¸­çš„åº•å±‚å·¥å…·å®ç°ï¼Œæä¾› Agno Agent å…¼å®¹çš„ Toolkit æ¥å£
"""
from datetime import datetime
from typing import Optional
from agno.tools import Toolkit
from loguru import logger

from utils.database_manager import DatabaseManager
from utils.news_tools import NewsNowTools, PolymarketTools
from utils.stock_tools import StockTools
from utils.search_tools import SearchTools
from utils.sentiment_tools import SentimentTools


class NewsToolkit(Toolkit):
    """
    æ–°é—»å·¥å…·åŒ… - åŒ…è£… NewsNowTools ä¸º Agno Toolkit
    
    æä¾›çƒ­ç‚¹æ–°é—»è·å–ã€å†…å®¹æå–ç­‰åŠŸèƒ½
    """
    
    def __init__(self, db: DatabaseManager, **kwargs):
        self._news_tools = NewsNowTools(db)
        self._sources = self._news_tools.SOURCES
        
        tools = [
            self.fetch_hot_news,
            self.fetch_news_content,
            self.get_unified_trends,
            self.enrich_news_content,
        ]
        super().__init__(name="news_toolkit", tools=tools, **kwargs)


    def fetch_hot_news(self, source_id: str, count: int = 10) -> str:
        """
        ä»æŒ‡å®šæ–°é—»æºè·å–çƒ­ç‚¹æ–°é—»åˆ—è¡¨ã€‚
        
        Args:
            source_id: æ–°é—»æºæ ‡è¯†ç¬¦ã€‚å¯é€‰å€¼æŒ‰ç±»åˆ«:
                **é‡‘èç±»**: "cls" (è´¢è”ç¤¾), "wallstreetcn" (åå°”è¡—è§é—»),
                           "xueqiu" (é›ªçƒ), "eastmoney" (ä¸œæ–¹è´¢å¯Œ), "yicai" (ç¬¬ä¸€è´¢ç»)
                **ç»¼åˆç±»**: "weibo" (å¾®åšçƒ­æœ), "zhihu" (çŸ¥ä¹çƒ­æ¦œ), "baidu" (ç™¾åº¦çƒ­æœ),
                           "toutiao" (ä»Šæ—¥å¤´æ¡), "douyin" (æŠ–éŸ³), "thepaper" (æ¾æ¹ƒæ–°é—»)
                **ç§‘æŠ€ç±»**: "36kr" (36æ°ª), "ithome" (ITä¹‹å®¶), "v2ex", "juejin" (æ˜é‡‘),
                           "hackernews" (Hacker News)
                æ¨èé‡‘èåˆ†æä½¿ç”¨ "cls", "wallstreetcn", "xueqiu"ã€‚
            count: è·å–çš„æ–°é—»æ•°é‡ï¼Œé»˜è®¤ 10 æ¡ã€‚
        
        Returns:
            çƒ­ç‚¹æ–°é—»åˆ—è¡¨çš„æ–‡æœ¬æè¿°ï¼ŒåŒ…å«æ’åã€æ ‡é¢˜å’Œé“¾æ¥ã€‚å¦‚æœæºä¸å¯ç”¨åˆ™è¿”å›é”™è¯¯ä¿¡æ¯ã€‚
        """
        logger.info(f"ğŸ”§ [TOOL CALLED] fetch_hot_news(source_id={source_id}, count={count})")
        
        items = self._news_tools.fetch_hot_news(source_id, count=count, fetch_content=False)
        
        if not items:
            return f"è·å– {source_id} çƒ­ç‚¹å¤±è´¥"
        
        source_name = self._sources.get(source_id, source_id)
        result = f"## {source_name} çƒ­ç‚¹ (è·å–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')})\n\n"
        
        for item in items:
            result += f"{item['rank']}. {item['title']}\n   é“¾æ¥: {item['url']}\n\n"
        
        logger.info(f"âœ… [TOOL SUCCESS] Got {len(items)} news items from {source_id}")
        return result

    def fetch_news_content(self, url: str) -> str:
        """
        ä½¿ç”¨ Jina Reader æŠ“å–æŒ‡å®š URL çš„ç½‘é¡µæ­£æ–‡å†…å®¹ã€‚
        
        Args:
            url: éœ€è¦æŠ“å–å†…å®¹çš„å®Œæ•´ç½‘é¡µ URLï¼Œå¿…é¡»ä»¥ http:// æˆ– https:// å¼€å¤´ã€‚
        
        Returns:
            æå–çš„ç½‘é¡µæ­£æ–‡å†…å®¹ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›é”™è¯¯ä¿¡æ¯ã€‚
        """
        content = self._news_tools.fetch_news_content(url)
        if content:
            return content[:5000]  # é™åˆ¶é•¿åº¦
        return "å†…å®¹æŠ“å–å¤±è´¥"

    def get_unified_trends(self, sources: str = "wallstreetcn,cls") -> str:
        """
        è·å–å¤šå¹³å°ç»¼åˆçƒ­ç‚¹æŠ¥å‘Šã€‚
        
        Args:
            sources: è¦æ‰«æçš„æ–°é—»æºï¼Œç”¨é€—å·åˆ†éš”ã€‚
                     å¯é€‰å€¼: weibo, zhihu, baidu, toutiao, wallstreetcn, cls
                     é»˜è®¤: "wallstreetcn,cls" (é‡‘èèµ„è®¯)
        
        Returns:
            æ ¼å¼åŒ–çš„çƒ­ç‚¹æ±‡æ€»æŠ¥å‘Šã€‚
        """
        source_list = [s.strip() for s in sources.split(",")]
        report = self._news_tools.get_unified_trends(source_list)
        return report

    def enrich_news_content(self, source: str = None, limit: int = 5) -> str:
        """
        ä¸ºæ•°æ®åº“ä¸­ç¼ºå°‘æ­£æ–‡å†…å®¹çš„æ–°é—»è¡¥å……å†…å®¹ã€‚
        
        Args:
            source: ç­›é€‰ç‰¹å®šæ–°é—»æºï¼ˆå¦‚ "cls"ï¼‰ï¼Œä¸ºç©ºåˆ™å¤„ç†æ‰€æœ‰ã€‚
            limit: æœ€å¤šå¤„ç†çš„æ–°é—»æ•°é‡ï¼Œé»˜è®¤ 5 æ¡ã€‚
        
        Returns:
            å¤„ç†ç»“æœçš„æè¿°ã€‚
        """
        logger.info(f"ğŸ”§ [TOOL CALLED] enrich_news_content(source={source}, limit={limit})")
        
        # è·å–éœ€è¦è¡¥å……å†…å®¹çš„æ–°é—»
        news_items = self._news_tools.db.get_daily_news(source=source, limit=limit)
        items_without_content = [n for n in news_items if not n.get('content')]
        
        if not items_without_content:
            return "æ²¡æœ‰éœ€è¦è¡¥å……å†…å®¹çš„æ–°é—»"
        
        updated_count = 0
        cursor = self._news_tools.db.conn.cursor()
        
        for item in items_without_content[:limit]:
            url = item.get('url')
            if url:
                content = self._news_tools.fetch_news_content(url)
                if content:
                    cursor.execute(
                        "UPDATE daily_news SET content = ? WHERE id = ?",
                        (content[:10000], item['id'])
                    )
                    updated_count += 1
        
        self._news_tools.db.conn.commit()
        logger.info(f"âœ… [TOOL SUCCESS] Enriched {updated_count} news items with content")
        
        return f"âœ… å·²ä¸º {updated_count} æ¡æ–°é—»è¡¥å……æ­£æ–‡å†…å®¹"


class PolymarketToolkit(Toolkit):
    """
    Polymarket é¢„æµ‹å¸‚åœºå·¥å…·åŒ… - è·å–çƒ­é—¨é¢„æµ‹å¸‚åœºæ•°æ®
    
    é¢„æµ‹å¸‚åœºæ•°æ®å¯åæ˜ å…¬ä¼—æƒ…ç»ªã€é¢„æœŸå’Œå…³æ³¨åº¦
    """
    
    def __init__(self, db: DatabaseManager, **kwargs):
        self._poly_tools = PolymarketTools(db)
        
        tools = [
            self.get_prediction_markets,
            self.get_market_summary,
        ]
        super().__init__(name="polymarket_toolkit", tools=tools, **kwargs)
    
    def get_prediction_markets(self, limit: int = 20) -> str:
        """
        è·å– Polymarket æ´»è·ƒé¢„æµ‹å¸‚åœºçš„å…³é”®æ•°æ®ã€‚
        
        é¢„æµ‹å¸‚åœºåæ˜ å…¬ä¼—å¯¹é‡å¤§äº‹ä»¶çš„æ¦‚ç‡é¢„æœŸï¼Œå¯ç”¨äº:
        - åˆ†æå¸‚åœºæƒ…ç»ªå’Œé£é™©åå¥½
        - äº†è§£çƒ­é—¨è¯é¢˜çš„å…³æ³¨åº¦
        - è·å–é‡å¤§äº‹ä»¶çš„æ¦‚ç‡é¢„æœŸ
        
        Args:
            limit: è·å–çš„å¸‚åœºæ•°é‡ï¼Œé»˜è®¤ 20 ä¸ªã€‚
        
        Returns:
            é¢„æµ‹å¸‚åœºæ•°æ®åˆ—è¡¨ï¼ŒåŒ…å«é—®é¢˜ã€ç»“æœæ¦‚ç‡å’Œäº¤æ˜“é‡ã€‚
            å¦‚æœè·å–å¤±è´¥è¿”å›é”™è¯¯ä¿¡æ¯ã€‚
        """
        logger.info(f"ğŸ”§ [TOOL CALLED] get_prediction_markets(limit={limit})")
        
        markets = self._poly_tools.get_active_markets(limit)
        if not markets:
            return "âŒ æ— æ³•è·å– Polymarket æ•°æ®ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰"
        
        result = f"## ğŸ”® Polymarket çƒ­é—¨é¢„æµ‹ (å…± {len(markets)} ä¸ª)\n\n"
        for i, m in enumerate(markets[:limit], 1):
            question = m.get("question", "Unknown")
            prices = m.get("outcomePrices", [])
            volume = m.get("volume", 0)
            
            result += f"{i}. **{question}**\n"
            if prices:
                result += f"   æ¦‚ç‡: {prices}\n"
            if volume:
                try:
                    result += f"   äº¤æ˜“é‡: ${float(volume):,.0f}\n"
                except:
                    result += f"   äº¤æ˜“é‡: {volume}\n"
            result += "\n"
        
        logger.info(f"âœ… [TOOL SUCCESS] Got {len(markets)} prediction markets")
        return result
    
    def get_market_summary(self, limit: int = 10) -> str:
        """
        è·å–é¢„æµ‹å¸‚åœºæ‘˜è¦æŠ¥å‘Šï¼Œäº†è§£å½“å‰çƒ­é—¨è¯é¢˜å’Œå…¬ä¼—é¢„æœŸã€‚
        
        Args:
            limit: è·å–çš„å¸‚åœºæ•°é‡ï¼Œé»˜è®¤ 10 ä¸ªã€‚
            
        Returns:
            æ ¼å¼åŒ–çš„é¢„æµ‹å¸‚åœºæŠ¥å‘Šã€‚
        """
        return self._poly_tools.get_market_summary(limit)


class StockToolkit(Toolkit):

    """
    è‚¡ç¥¨å·¥å…·åŒ… - åŒ…è£… StockTools ä¸º Agno Toolkit
    
    æä¾›è‚¡ç¥¨æœç´¢ã€ä»·æ ¼æŸ¥è¯¢ç­‰åŠŸèƒ½
    """
    
    def __init__(self, db: DatabaseManager, **kwargs):
        self._stock_tools = StockTools(db)
        
        tools = [
            self.search_ticker,
            self.get_stock_price,
        ]
        super().__init__(name="stock_toolkit", tools=tools, **kwargs)

    def search_ticker(self, query: str) -> str:
        """
        æ¨¡ç³Šæœç´¢ A è‚¡è‚¡ç¥¨ä»£ç æˆ–åç§°ã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼Œå¯ä»¥æ˜¯è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ "600519"ï¼‰æˆ–åç§°å…³é”®è¯ï¼ˆå¦‚ "èŒ…å°"ã€"å®å¾·"ã€"æ¯”äºšè¿ª"ï¼‰ã€‚
        
        Returns:
            åŒ¹é…çš„è‚¡ç¥¨åˆ—è¡¨ï¼ŒåŒ…å«ä»£ç å’Œåç§°ã€‚
        """
        results = self._stock_tools.search_ticker(query)
        
        if not results:
            return f"æœªæ‰¾åˆ°åŒ¹é… '{query}' çš„è‚¡ç¥¨"
        
        output = f"## è‚¡ç¥¨æœç´¢ç»“æœ (å…³é”®è¯: {query})\n\n"
        for r in results:
            output += f"- {r['code']} - {r['name']}\n"
        return output

    def get_stock_price(self, ticker: str, days: int = 30) -> str:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„è¿‘æœŸä»·æ ¼èµ°åŠ¿ã€‚
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "600519"ï¼ˆè´µå·èŒ…å°ï¼‰æˆ– "000001"ï¼ˆå¹³å®‰é“¶è¡Œï¼‰ã€‚
            days: æŸ¥è¯¢å¤©æ•°ï¼Œé»˜è®¤ 30 å¤©ã€‚
        
        Returns:
            ä»·æ ¼èµ°åŠ¿çš„æ–‡æœ¬æ‘˜è¦ã€‚
        """
        from datetime import timedelta
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
        
        df = self._stock_tools.get_stock_price(ticker, start_date, end_date)
        
        if df.empty:
            return f"æœªèƒ½è·å– {ticker} çš„è‚¡ä»·æ•°æ®"
        
        latest = df.iloc[-1]
        change = ((latest['close'] - df.iloc[0]['close']) / df.iloc[0]['close']) * 100
        
        return f"""## {ticker} ä»·æ ¼èµ°åŠ¿ ({days}å¤©)
- å½“å‰ä»·: Â¥{latest['close']:.2f}
- æœŸé—´æ¶¨è·Œ: {change:+.2f}%
- æœ€é«˜/æœ€ä½: Â¥{df['high'].max():.2f} / Â¥{df['low'].min():.2f}
- æ•°æ®èŒƒå›´: {df.iloc[0]['date']} -> {latest['date']}"""


class SentimentToolkit(Toolkit):
    """
    æƒ…ç»ªåˆ†æå·¥å…·åŒ… - åŒ…è£… SentimentTools ä¸º Agno Toolkit
    
    æä¾›æ–‡æœ¬æƒ…ç»ªåˆ†æåŠŸèƒ½ï¼ˆæ”¯æŒ BERT å’Œ LLM æ¨¡å¼ï¼‰
    """
    
    def __init__(self, db: DatabaseManager, mode: str = "auto", **kwargs):
        self._sentiment_tools = SentimentTools(db, mode=mode)
        self._db = db
        
        tools = [
            self.analyze_sentiment,
            self.batch_update_sentiment,
        ]
        super().__init__(name="sentiment_toolkit", tools=tools, **kwargs)

    def analyze_sentiment(self, text: str) -> str:
        """
        åˆ†ææ–‡æœ¬çš„æƒ…ç»ªææ€§ã€‚
        
        Args:
            text: éœ€è¦åˆ†æçš„æ–‡æœ¬å†…å®¹ï¼Œå¦‚æ–°é—»æ ‡é¢˜æˆ–æ‘˜è¦ã€‚
        
        Returns:
            æƒ…ç»ªåˆ†æç»“æœï¼ŒåŒ…å«åˆ†å€¼(-1.0åˆ°1.0)å’Œæ ‡ç­¾(positive/negative/neutral)ã€‚
        """
        result = self._sentiment_tools.analyze_sentiment(text)
        
        score = result.get('score', 0.0)
        label = result.get('label', 'neutral')
        reason = result.get('reason', '')
        
        return f"""æƒ…ç»ªåˆ†æç»“æœ:
- æ–‡æœ¬: {text[:100]}{'...' if len(text) > 100 else ''}
- åˆ†å€¼: {score:.2f}
- æ ‡ç­¾: {label}
- åˆ†æ: {reason}"""

    def batch_update_sentiment(self, source: str = None, limit: int = 20) -> str:
        """
        æ‰¹é‡æ›´æ–°æ•°æ®åº“ä¸­æ–°é—»çš„æƒ…ç»ªåˆ†æ•°ã€‚
        
        Args:
            source: ç­›é€‰ç‰¹å®šæ–°é—»æºï¼ˆå¦‚ "cls", "wallstreetcn"ï¼‰ï¼Œä¸ºç©ºåˆ™å¤„ç†æ‰€æœ‰ã€‚
            limit: æœ€å¤šå¤„ç†çš„æ–°é—»æ•°é‡ï¼Œé»˜è®¤ 20 æ¡ã€‚
        
        Returns:
            æ›´æ–°ç»“æœçš„æè¿°ã€‚
        """
        logger.info(f"ğŸ”§ [TOOL CALLED] batch_update_sentiment(source={source}, limit={limit})")
        
        count = self._sentiment_tools.batch_update_news_sentiment(source=source, limit=limit)
        
        return f"âœ… å·²æ›´æ–° {count} æ¡æ–°é—»çš„æƒ…ç»ªåˆ†æ•°"



class SearchToolkit(Toolkit):
    """
    æœç´¢å·¥å…·åŒ… - åŒ…è£… SearchTools ä¸º Agno Toolkit
    
    æä¾›ç½‘ç»œæœç´¢åŠŸèƒ½ï¼ˆæ”¯æŒ DuckDuckGo å’Œç™¾åº¦ï¼‰
    """
    
    def __init__(self, db: DatabaseManager, **kwargs):
        self._search_tools = SearchTools(db)
        
        tools = [
            self.web_search,
            self.aggregate_search,
        ]
        super().__init__(name="search_toolkit", tools=tools, **kwargs)

    def web_search(self, query: str, engine: str = "ddg", max_results: int = 5) -> str:
        """
        ä½¿ç”¨æŒ‡å®šæœç´¢å¼•æ“æ‰§è¡Œç½‘ç»œæœç´¢ã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼Œå¦‚ "è‹±ä¼Ÿè¾¾è´¢æŠ¥" æˆ– "å…‰ä¼è¡Œä¸šæ”¿ç­–"ã€‚
            engine: æœç´¢å¼•æ“é€‰æ‹©ã€‚å¯é€‰å€¼: "ddg" (DuckDuckGo), "baidu" (ç™¾åº¦)ã€‚
            max_results: è¿”å›ç»“æœæ•°é‡ã€‚é»˜è®¤ 5ã€‚
        
        Returns:
            æœç´¢ç»“æœçš„æ–‡æœ¬æè¿°ã€‚
        """
        return self._search_tools.search(query, engine=engine, max_results=max_results)

    def aggregate_search(self, query: str, max_results: int = 5) -> str:
        """
        åŒæ—¶ä½¿ç”¨å¤šä¸ªæœç´¢å¼•æ“æœç´¢å¹¶èšåˆç»“æœã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯ã€‚
            max_results: æ¯ä¸ªå¼•æ“è¿”å›çš„æœ€å¤§ç»“æœæ•°ã€‚é»˜è®¤ 5ã€‚
        
        Returns:
            èšåˆåçš„æœç´¢ç»“æœã€‚
        """
        return self._search_tools.aggregate_search(query, max_results=max_results)


class ContextSearchToolkit(Toolkit):
    """
    ä¸Šä¸‹æ–‡æœç´¢å·¥å…·åŒ… - ç”¨äº RAG åœºæ™¯çš„æ–‡æ¡£ç‰‡æ®µæ£€ç´¢
    
    æ”¯æŒåœ¨å†…å­˜ä¸­å­˜å‚¨æ–‡æ¡£ç‰‡æ®µï¼Œå¹¶é€šè¿‡å…³é”®è¯æœç´¢ç›¸å…³å†…å®¹ã€‚
    é€‚ç”¨äº ReportAgent çš„åˆ†æ®µç¼–è¾‘åœºæ™¯ã€‚
    """
    
    def __init__(self, **kwargs):
        self._store = {}  # {doc_id: {"title": str, "content": str, "summary": str}}
        
        tools = [
            self.search_context,
            self.get_toc,
        ]
        super().__init__(name="context_search_toolkit", tools=tools, **kwargs)
    
    def add_document(self, doc_id: str, title: str, content: str, summary: str = ""):
        """æ·»åŠ æ–‡æ¡£åˆ°å­˜å‚¨ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼Œé LLM å·¥å…·ï¼‰"""
        self._store[doc_id] = {
            "title": title,
            "content": content,
            "summary": summary or content[:200] + "..."
        }
        logger.info(f"ğŸ“„ Added document to context store: {doc_id} - {title[:30]}...")
    
    def clear(self):
        """æ¸…ç©ºæ–‡æ¡£å­˜å‚¨"""
        self._store.clear()
        logger.info("ğŸ—‘ï¸ Context store cleared")
    
    def search_context(self, query: str, max_results: int = 3) -> str:
        """
        åœ¨å·²å­˜å‚¨çš„æ–‡æ¡£ä¸­æœç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„å†…å®¹ç‰‡æ®µã€‚
        
        Args:
            query: æœç´¢å…³é”®è¯ï¼Œå¦‚ "æ¶ˆè´¹æ¿å—" æˆ– "èŒ…å° é¢„æµ‹"ã€‚
            max_results: è¿”å›çš„æœ€å¤§ç»“æœæ•°ï¼Œé»˜è®¤ 3ã€‚
        
        Returns:
            åŒ¹é…çš„æ–‡æ¡£ç‰‡æ®µï¼ŒæŒ‰ç›¸å…³æ€§æ’åºã€‚
        """
        logger.info(f"ğŸ” [TOOL CALLED] search_context(query={query}, max_results={max_results})")
        
        if not self._store:
            return "âš ï¸ ä¸Šä¸‹æ–‡å­˜å‚¨ä¸ºç©ºï¼Œæ— å¯æœç´¢å†…å®¹ã€‚"
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é… + è®¡åˆ†
        query_terms = query.lower().split()
        results = []
        
        for doc_id, doc in self._store.items():
            score = 0
            content_lower = doc["content"].lower()
            title_lower = doc["title"].lower()
            
            for term in query_terms:
                # æ ‡é¢˜åŒ¹é…æƒé‡æ›´é«˜
                if term in title_lower:
                    score += 3
                if term in content_lower:
                    score += content_lower.count(term)
            
            if score > 0:
                results.append((score, doc_id, doc))
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x[0], reverse=True)
        results = results[:max_results]
        
        if not results:
            return f"æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„å†…å®¹ã€‚"
        
        output = f"## æœç´¢ç»“æœ (æŸ¥è¯¢: {query})\n\n"
        for score, doc_id, doc in results:
            output += f"### [{doc_id}] {doc['title']}\n"
            # è¿”å›æ‘˜è¦è€Œéå…¨æ–‡ï¼ŒèŠ‚çœ token
            output += f"{doc['summary']}\n\n"
        
        logger.info(f"âœ… [TOOL SUCCESS] Found {len(results)} matching documents")
        return output
    
    def get_toc(self) -> str:
        """
        è·å–å½“å‰å­˜å‚¨çš„æ‰€æœ‰æ–‡æ¡£çš„ç›®å½•ï¼ˆTOCï¼‰ã€‚
        
        Returns:
            æ–‡æ¡£ç›®å½•åˆ—è¡¨ï¼ŒåŒ…å« ID å’Œæ ‡é¢˜ã€‚
        """
        logger.info("ğŸ” [TOOL CALLED] get_toc()")
        
        if not self._store:
            return "âš ï¸ ä¸Šä¸‹æ–‡å­˜å‚¨ä¸ºç©ºã€‚"
        
        output = "## æ–‡æ¡£ç›®å½• (TOC)\n\n"
        for doc_id, doc in self._store.items():
            output += f"- **[{doc_id}]** {doc['title']}\n"
        
        return output

